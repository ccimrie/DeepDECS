<!DOCTYPE html>
<html lang="en">
<head>
<title>DeepDECS</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
       <script type="text/x-mathjax-config">
         MathJax.Hub.Config({
           tex2jax: {
             inlineMath: [ ['$','$'], ["\\(","\\)"] ],
             processEscapes: true
           }
         });
       </script>
       <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<style>
body,h1,h2,h3,h4,h5,h6 {font-family: "Lato", sans-serif}
.w3-bar,h1,button {font-family: "Montserrat", sans-serif}
.fa-anchor,.fa-coffee {font-size:200px}
div.pdf-aug {
  width:  35%;
  float:  left;
  display: flex;
  align-items: center;
  justify-content: center;
}
div.text-middle {
  width: 20%;
  max-width: 100%;
  float:  left;
}
div.text-left {
  width: 35%;
  max-width: 100%;
  float:  left;
}
div.text-right {
  width: 35%;
  max-width: 100%;
  /*float:  left;*/
}
div.button-centre
{
  float:  left;
  align-items: center;
  justify-content: center;
  display:  flex;
}
div.centre-div
{
  align-items: center;
  justify-content: center;
  display:  flex;
}
div.image-centre
{
  width: 45%;
  align-items: center;
  justify-content: center;
  display:  flex;
}
div.image-left
{
  width: 35%;
  align-items: center;
  justify-content: center;
  display:  flex;
}
div.push-right
{
  padding-right: 20px;
}
div.row
{
  width:  100%
  display: flex;
}
div.col {
  flex: 1; /* additionally, equal width */
  
  padding: 1em;
  border: solid;
}
div.centre-div
{
  align-items: center;
  justify-content: center;
  display:  flex;
}
a:link {
  color: blue;
  background-color: transparent;
  text-decoration: underline;
}
a:visited {
  color: hotpink;
  text-decoration: underline;
}
</style>
</head>
<body>

<!-- Header -->
<header class="w3-container w3-blue w3-center" style="padding:32px 16px">
  <h1 class="w3-margin w3-jumbo">DeepDECS</h1>
  <h1 class="w3-xxlarge">Discrete-Event Controller Synthesis for Autonomous Systems with
  <br>
  Deep-Learning Perception Components</h1>
  <h1 class="w3-margin w3-xlarge"><a href="https://www-users.york.ac.uk/~rcc516/" target="_blank" style='color: white;'>Radu Calinescu</a>, <a href="https://www.cs.york.ac.uk/people/?group=All%20Staff&username=cimrie" target="_blank" style='color: white;'> Calum Imrie</a>, <a href=" https://www.andrew.cmu.edu/user/rmangal/" target="_blank" style='color: white;'>Ravi Mangal</a>, <a href="https://genaina.github.io/" target="_blank" style='color: white;'>Genaína Nunes Rodrigues</a>, <a href="https://www.andrew.cmu.edu/user/pcorina/" target="_blank" style='color: white;'>Corina P<span>&#259;</span>s<span>&#259;</span>reanu</a>, Misael Alpizar Santana, and <a href="https://www.cs.york.ac.uk/people/?group=Research%20Students&username=gricel" target="_blank" style='color: white;'>Gricel Vázquez</a></h1>
</header>

<!-- Grid 1: DeepDECS -->
<div class="w3-padding-32 w3-container w3-large">
  <div class="row centre-div">
    <div class="text-left">
      <h1>DeepDECS controller synthesis process</h1>
      <p class="w3-text-grey">Many autonomous systems use deep neural networks (DNNs) to perceive the world around them. 
             However, no DNN is perfect, which can be devastating in safety-critical applications. 
             DeepDECS is a controller synthesis method that captures the uncertainty of DNN perception components 
             through the use of DNN verification techniques. 
             From this, it produces correct-by-construction controllers for such autonomous systems.</p>

      <p class="w3-text-grey">The diagram on the right depicts the DeepDECS controller synthesis process, 
             including its four inputs. The first is a discrete-time Markov Chain (DTMC) modelling the behaviour of the
             autonomous system within its application (assuming perfect perception); the second is a set of requirements
             specified in probabilistic computation tree logic (PCTL). The third input is a pre-trained perception DNN that
             will be utilised in the autonomous system, and the fourth is a representative test dataset for this DNN. 
             These last two inputs are utilised, along with \(n\) verification methods, in Stage 1 ('DNN uncertainty quantification')
             of DeepDECS to derive a set of \(2^{n}\) confusion matrices. These confusion matrices are then used to estimate the DNN
             classification/misclassification probabilities  for an augmented, DNN-perception DTMC obtained automatically in Stage 2
             ('Model augmentation') of DeepDECS. The augmented model contains an accurate representation of the imperfect DNN
             perception component. Finally, Stage 3 ('Controller synthesis') of DeepDECS employs probabilistic model checking techniques
             to generate the autonomous system controller synthesis.</p>
    </div>
    <div class="w3-center image-centre">
      <embed style='height: 95%; width: 95%; object-fit: contain' src="images/DeepDECS-approach.png"/>
    </div>
  </div>
  <DIV STYLE="background-color:#000000; height:6px; width:100%;">
</div>

<DIV STYLE="background-color:#000000; height:6px; width:100%;">
<!-- Grid 2: Case Studies -->
<div class="w3-light-grey w3-padding-32 w3-container w3-large">
  <div class="row centre-div">
    <div class="image-left w3-center">
          <embed style='height: 95%; width: 70%; object-fit: contain' src="images/mobile-robot-plan.png"/>
          <a href="https://drive.google.com/file/d/1jocqL7-QXZ7Hk6G1aUmd10oF73tsMJzf/view?usp=share_link" target="_blank">
          <span class="twemoji filledIconsBlue"><svg style='width: 45%;' viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 10.5V7a1 1 0 0 0-1-1H4a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1v-3.5l4 4v-11l-4 4Z"></path></svg></span>
          </a>
    </div>
    <div class="text-right">
      <h1>Case studies</h1>
      <h5 class="w3-padding-4">Mobile robot collision limitation</h5>
      <p class="w3-text-grey">
        Inspired by recent research on the integration of DNNs with a wide variety of autonomous systems we used DeepDECS to develop a 
        mobile robot collision-limitation controller. We considered a robot travelling between locations A and B  via waypoints(see left), 
        where the robot (blue) may encounter and potentially collide with another moving agent (red). As such, the robot uses DNN 
        perception at each waypoint, to assess if it is on a collision course. The DNN's inputs are the distance between the robot and 
        collider (\(x\), \(y\)), the linear and angular velocity of the collider (\(s\), \(\dot{\theta}\)), and the initial heading of the 
        collider (\(\theta\)). The input values are all relative to the robot's local reference frame. Based on the DNN output, its 
        controller decides whether the robot will proceed to the next waypoint or should wait for a while at its current one. The 
        requirements for the robot is to minimise the time and minimise the risk of a dangerous collision when travelling between two 
        waypoints.
      </p>
      <p class="w3-text-grey">
        Clicking on the camera icon on the left will open a video visualising a simulation of a robot travelling between two locations 
        using a controller synthesised by the DeepDECS process.
      </p>
    </div>
  </div>
  <div class="row centre-div">
    <div class="image-left w3-center">
        <embed src="images/SafeSCAD-system.png" width="70%" height="70%"/>
    </div>
    <div class="text-right">
        <h5 class="w3-padding-4">Driver-attentiveness management</h5>
        <p class="w3-text-grey">
          We used DEEPDECS to design a proof-of-concept driver-attentiveness management system for shared-control autonomous cars. Developed as part of our <a href="https://www.york.ac.uk/assuring-autonomy/demonstrators/autonomous-driving/" target="_blank">SafeSCAD</a> project and inspired by the first United Nations regulation on vehicles with Level 3 automation, this system uses: (i) specialised sensors to monitor key car parameters (velocity, lane position, etc.) and driver’s biometrics (eye movement, heart rate, etc.), (ii) a three-class DNN to predict the driver’s response to a request to resume manual driving, and (iii) a deterministic controller to issue visual/acoustic/haptic alerts when the driver is insufficiently attentive. We used an existing DNN (<a href="https://dl.acm.org/doi/fullHtml/10.1145/3411764.3445563" target="_blank">DeepTake</a>) trained and validated with driver data from a SafeSCAD user study performed within a driving simulator, with the test dataset used for our DNN uncertainty quantification obtained from the same study. The requirements for the controller is to minimise the risk, which is dependant upon the driver's attentiveness level, and to minimise the nuisance caused to the driver through the usage of alerts.
        </p>    
    </div>
  </div>
  <DIV STYLE="background-color:#000000; height:6px; width:100%;">
</div>

<!-- <DIV STYLE="background-color:#000000; height:10px; width:100%;"> -->
<!-- Grid 3: Github repo -->
<div class="w3-padding-32 w3-container w3-large">
  <div class="row centre-div">
    <div class="text-left">
      <h1>Github repository</h1>
      <p class="w3-text-grey">
        An <a href="https://github.com/ccimrie/DeepDECS/tree/master/augment_tool" target="_blank">augment tool</a> that automates Stage 2 of DeepDECS, a <a href="https://github.com/ccimrie/DeepDECS/tree/master/tutorial" target="_blank">DeepDECS tutorial</a>, and all the models, DNNs, datasets from the two <a href="https://github.com/ccimrie/DeepDECS/tree/master/case_studies" target="_blank">case studies</a> are freely available in our <a href="https://github.com/ccimrie/DeepDECS" target="_blank">Github repo</a>.
      </p>
    </div>
  </div>
  <DIV STYLE="background-color:#000000; height:6px; width:100%;">
</div>

  <!-- Grid 4: acknowledgements -->
<div class="w3-light-grey w3-padding-32 w3-container w3-large">
  <div class="row centre-div">
    <div class="text-right">
      <h1 align=right>Acknowledgements</h1>
      <p class="w3-text-grey">
       This project has received funding from the UKRI project ‘Trustworthy Autonomous Systems Node in Resilience’, the UKRI Global Research and Innovation Programme, and the Assuring Autonomy International Programme. The authors are grateful to the developers of the DeepTake deep neural network for sharing the DeepTake data sets, and to the University of York’s Viking research computing cluster team for providing access to their systems.
      </p>
    </div>
  </div>
</div>

<!-- Footer -->
<!-- <footer class="w3-container w3-padding-64 w3-center w3-opacity">  
  <div class="w3-xlarge w3-padding-32">
    <i class="fa fa-facebook-official w3-hover-opacity"></i>
    <i class="fa fa-instagram w3-hover-opacity"></i>
    <i class="fa fa-snapchat w3-hover-opacity"></i>
    <i class="fa fa-pinterest-p w3-hover-opacity"></i>
    <i class="fa fa-twitter w3-hover-opacity"></i>
    <i class="fa fa-linkedin w3-hover-opacity"></i>
 </div>
 <p>Powered by <a href="https://www.w3schools.com/w3css/default.asp" target="_blank">w3.css</a></p>
</footer> -->

</body>
</html>
